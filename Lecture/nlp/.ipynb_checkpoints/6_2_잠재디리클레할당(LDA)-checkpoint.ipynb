{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42193\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import os,io\n",
    "\n",
    "files = os.listdir(os.getcwd()+'/data/spao_reviews/')\n",
    "result_df =pd.DataFrame()\n",
    "for file in files : \n",
    "    df=pd.read_parquet(os.getcwd()+'/data/spao_reviews/' + file)\n",
    "    \n",
    "    result_df = pd.concat([result_df,df])\n",
    "print(len(result_df))\n",
    "result_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeong_jaekeun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'소재도 원하던 디자인대로 상품도 나왔습니다'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result_df['clean_Doc'] = result_df['rev_cont'].str.replace(\"[^a-zA-Z가-힣]\", \" \") #특수문자제거\n",
    "result_df['clean_Doc'] = result_df['clean_Doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2])) \n",
    "#영어는 3글자 한글은 2글자 이상 제거\n",
    "\n",
    "result_df['clean_Doc'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english') # NLTK로부터 불용어를 받아옵니다.\n",
    "tokenized_doc = result_df['clean_Doc'].apply(lambda x: x.split()) # 토큰화\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            [testest]\n",
       "1                                           [testtest]\n",
       "2                                         [좋아요, 감사합니다]\n",
       "3    [바람막이용으로, 편하고, 어떠한, 장소에, 편하게, 윈드브레이커입니다, L사이즈를...\n",
       "4                        [소재도, 원하던, 디자인대로, 상품도, 나왔습니다]\n",
       "Name: clean_Doc, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeong_jaekeun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.086*\"좋아요\" + 0.028*\"좋습니다\" + 0.026*\"사이즈도\" + 0.024*\"예뻐요\" + 0.020*\"같아요\" + 0.018*\"편하고\" + 0.017*\"따뜻하고\"')\n",
      "(1, '0.035*\"같아요\" + 0.027*\"좋아요\" + 0.020*\"사이즈\" + 0.017*\"이뻐요\" + 0.013*\"생각보다\" + 0.012*\"샀는데\" + 0.011*\"사이즈가\"')\n",
      "(2, '0.015*\"맘에들어요\" + 0.015*\"소재가\" + 0.014*\"시원한\" + 0.009*\"느낌이\" + 0.009*\"길이가\" + 0.007*\"아이가\" + 0.007*\"재질이\"')\n",
      "(3, '0.045*\"마음에\" + 0.030*\"들어요\" + 0.018*\"배송도\" + 0.018*\"좋아요\" + 0.017*\"듭니다\" + 0.011*\"감사합니다\" + 0.011*\"빠르고\"')\n",
      "(4, '0.066*\"좋네요\" + 0.027*\"구매했어요\" + 0.011*\"괜찮아요\" + 0.009*\"않아서\" + 0.007*\"괜찮네요\" + 0.006*\"귀여워요\" + 0.005*\"짱짱하고\"')\n",
      "(5, '0.015*\"스파오\" + 0.014*\"구매했습니다\" + 0.012*\"가격에\" + 0.010*\"이쁩니다\" + 0.009*\"있어요\" + 0.009*\"저렴하게\" + 0.009*\"샀어요\"')\n",
      "(6, '0.009*\"재구매\" + 0.008*\"그대로\" + 0.007*\"입었는데\" + 0.007*\"합니다\" + 0.007*\"선물로\" + 0.007*\"구입했어요\" + 0.006*\"프린팅이\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 7 #20개의 토픽, k=20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=7)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.086*\"좋아요\" + 0.028*\"좋습니다\" + 0.026*\"사이즈도\" + 0.024*\"예뻐요\" + 0.020*\"같아요\" + 0.018*\"편하고\" + 0.017*\"따뜻하고\" + 0.013*\"귀여워요\" + 0.013*\"재질도\" + 0.012*\"편해요\" + 0.012*\"부드럽고\" + 0.012*\"예쁘고\" + 0.012*\"이쁘고\" + 0.011*\"여름에\" + 0.010*\"시원하고\" + 0.010*\"만족합니다\" + 0.010*\"사이즈\" + 0.010*\"가볍고\" + 0.009*\"편하게\" + 0.008*\"따뜻해요\"')\n",
      "\n",
      "(1, '0.035*\"같아요\" + 0.027*\"좋아요\" + 0.020*\"사이즈\" + 0.017*\"이뻐요\" + 0.013*\"생각보다\" + 0.012*\"샀는데\" + 0.011*\"사이즈가\" + 0.011*\"편하게\" + 0.011*\"있어서\" + 0.009*\"예뻐요\" + 0.009*\"맞아요\" + 0.009*\"사이즈는\" + 0.008*\"매장에서\" + 0.008*\"그래도\" + 0.008*\"입으려고\" + 0.007*\"여름에\" + 0.007*\"입으면\" + 0.006*\"입어도\" + 0.006*\"입어보고\" + 0.006*\"입는데\"')\n",
      "\n",
      "(2, '0.015*\"맘에들어요\" + 0.015*\"소재가\" + 0.014*\"시원한\" + 0.009*\"느낌이\" + 0.009*\"길이가\" + 0.007*\"아이가\" + 0.007*\"재질이\" + 0.007*\"기장이\" + 0.007*\"바지가\" + 0.006*\"좋아해요\" + 0.006*\"널널하니\" + 0.006*\"간절기에\" + 0.005*\"편이라\" + 0.005*\"보이는\" + 0.005*\"스파오\" + 0.005*\"굉장히\" + 0.005*\"생각보다\" + 0.005*\"좋았습니다\" + 0.005*\"딱이네요\" + 0.005*\"여름에\"')\n",
      "\n",
      "(3, '0.045*\"마음에\" + 0.030*\"들어요\" + 0.018*\"배송도\" + 0.018*\"좋아요\" + 0.017*\"듭니다\" + 0.011*\"감사합니다\" + 0.011*\"빠르고\" + 0.009*\"사이즈도\" + 0.009*\"입니다\" + 0.009*\"편합니다\" + 0.008*\"사이즈\" + 0.008*\"잘맞아요\" + 0.008*\"스파오\" + 0.008*\"가격도\" + 0.007*\"좋습니다\" + 0.007*\"이쁘네요\" + 0.007*\"딱입니다\" + 0.006*\"샀는데\" + 0.006*\"저렴하고\" + 0.006*\"잠옷으로\"')\n",
      "\n",
      "(4, '0.066*\"좋네요\" + 0.027*\"구매했어요\" + 0.011*\"괜찮아요\" + 0.009*\"않아서\" + 0.007*\"괜찮네요\" + 0.006*\"귀여워요\" + 0.005*\"짱짱하고\" + 0.005*\"컬러도\" + 0.005*\"좋습니당\" + 0.005*\"구매했는데\" + 0.004*\"다리가\" + 0.004*\"개인적으로\" + 0.004*\"색깔별로\" + 0.004*\"편안한\" + 0.004*\"샀는데\" + 0.004*\"좋네여\" + 0.004*\"확실히\" + 0.004*\"스타일\" + 0.004*\"만족스러워요\" + 0.004*\"이것만\"')\n",
      "\n",
      "(5, '0.015*\"스파오\" + 0.014*\"구매했습니다\" + 0.012*\"가격에\" + 0.010*\"이쁩니다\" + 0.009*\"있어요\" + 0.009*\"저렴하게\" + 0.009*\"샀어요\" + 0.008*\"좋아용\" + 0.008*\"샀습니다\" + 0.008*\"가성비\" + 0.007*\"만족합니다\" + 0.007*\"좋아서\" + 0.007*\"만족해요\" + 0.006*\"구매해서\" + 0.006*\"구매하고\" + 0.006*\"저렴한\" + 0.005*\"품질도\" + 0.005*\"일부러\" + 0.005*\"보들보들\" + 0.005*\"착용했을\"')\n",
      "\n",
      "(6, '0.009*\"재구매\" + 0.008*\"그대로\" + 0.007*\"입었는데\" + 0.007*\"합니다\" + 0.007*\"선물로\" + 0.007*\"구입했어요\" + 0.006*\"프린팅이\" + 0.006*\"스파오\" + 0.006*\"바지는\" + 0.005*\"입을게요\" + 0.005*\"왔어요\" + 0.005*\"있을것\" + 0.005*\"귀여워요\" + 0.005*\"귀여워용\" + 0.004*\"추천합니다\" + 0.004*\"배송이\" + 0.004*\"했습니다\" + 0.004*\"해리포터\" + 0.004*\"너무너무\" + 0.004*\"이렇게\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_words=20)\n",
    "for topic in topics:\n",
    "    \n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
